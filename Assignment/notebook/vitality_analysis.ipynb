{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "472c3aa2",
   "metadata": {},
   "source": [
    "## Phase 1: Data Ingestion & Clinical Sanitation\n",
    "\n",
    "### Objective\n",
    "Transform raw, error-prone clinical encounter data into a reliable analytical dataset suitable for downstream analysis and modeling.\n",
    "\n",
    "### Rationale\n",
    "\n",
    "Clinical databases are inherently messy due to:\n",
    "- Non-standard representations of missing values\n",
    "- Legacy coding systems\n",
    "- Data entry errors\n",
    "- Administrative outcomes (e.g., death) that invalidate predictive targets\n",
    "\n",
    "This phase establishes a **clean analytical baseline** by enforcing consistent null handling, removing structurally invalid records, and stabilizing categorical identifiers.\n",
    "\n",
    "### Key Decisions\n",
    "\n",
    "1. **Standardizing Missing Values**\n",
    "   - The dataset uses `'?'` to represent missing values.\n",
    "   - These are converted to NumPy `NaN` to enable proper statistical handling.\n",
    "\n",
    "2. **Dropping the `weight` Column**\n",
    "   - The `weight` feature exhibits >90% missingness.\n",
    "   - Imputation would be statistically meaningless and introduce bias.\n",
    "   - This limitation is documented as a data quality constraint.\n",
    "\n",
    "3. **Handling Invalid Gender Values**\n",
    "   - `Unknown/Invalid` is treated as missing, not as a valid category.\n",
    "\n",
    "4. **Removing Deceased Patients**\n",
    "   - Patients who expire or enter hospice cannot be readmitted.\n",
    "   - Including them would inject label noise into readmission analysis.\n",
    "   - Discharge disposition codes corresponding to death/hospice are identified via `IDs_mapping.csv`.\n",
    "\n",
    "5. **Deduplication**\n",
    "   - Exact duplicate rows indicate data entry or ETL errors and are removed.\n",
    "\n",
    "6. **Stabilizing Categorical Identifiers**\n",
    "   - Administrative ID columns are cast to strings to prevent numerical misinterpretation.\n",
    "\n",
    "The output of this phase is a **sanitized encounter-level dataset**, persisted to disk for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4069145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- IMPORTING LIBRARIES ---\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Configuration to display all columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3107c7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- STARTING PHASE 1: DATA INGESTION & CLINICAL SANITATION ---\")\n",
    "\n",
    "def load_and_sanitize_data(data_path, id_map_path):\n",
    "    \"\"\"\n",
    "    Phase 1 sanitation pipeline:\n",
    "    - Standardize missing values\n",
    "    - Audit schema\n",
    "    - Drop structurally invalid features\n",
    "    - Remove deceased patient encounters\n",
    "    - Deduplicate exact duplicates\n",
    "    - Stabilize categorical identifiers\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Ingest Data & Standardize Missing Values\n",
    "    df = pd.read_csv(data_path, na_values='?')\n",
    "    print(f\"Dataset loaded. Initial shape: {df.shape}\")\n",
    "\n",
    "    # 2. Initial Audit (Schema & Data Types)\n",
    "    print(\"\\n--- SCHEMA OVERVIEW ---\")\n",
    "    df.info()\n",
    "\n",
    "    print(\"\\n--- NUMERICAL SUMMARY ---\")\n",
    "    print(df.describe())\n",
    "\n",
    "    print(\"\\n--- COLUMN SCHEMA ---\")\n",
    "    print(df.columns.tolist())\n",
    "\n",
    "    # 3. Drop Weight Column (>90% Missingness)\n",
    "    if 'weight' in df.columns:\n",
    "        missing_rate = df['weight'].isna().mean()\n",
    "        print(f\"\\nWeight missingness: {missing_rate:.2%}\")\n",
    "\n",
    "        if missing_rate > 0.90:\n",
    "            df = df.drop(columns=['weight'])\n",
    "            print(\"Dropped 'weight' due to excessive missingness (>90%).\")\n",
    "\n",
    "    # 4. Handle Invalid Gender Values\n",
    "    if 'gender' in df.columns:\n",
    "        invalid_count = (df['gender'] == 'Unknown/Invalid').sum()\n",
    "        df.loc[df['gender'] == 'Unknown/Invalid', 'gender'] = np.nan\n",
    "        print(f\"Converted {invalid_count} invalid gender entries to NaN.\")\n",
    "\n",
    "    # 5. Remove Deceased / Hospice Patients\n",
    "    id_map = pd.read_csv(id_map_path, header=None, names=['id', 'description'])\n",
    "\n",
    "    # Extract discharge disposition section from semi-structured mapping file\n",
    "    start = id_map[id_map['id'] == 'discharge_disposition_id'].index[0] + 1\n",
    "    end = id_map[id_map['id'] == 'admission_source_id'].index[0]\n",
    "\n",
    "    discharge_map = id_map.iloc[start:end].copy()\n",
    "    discharge_map['id'] = pd.to_numeric(discharge_map['id'], errors='coerce')\n",
    "\n",
    "    # Identify expired or hospice-related codes\n",
    "    expired_codes = discharge_map[\n",
    "        discharge_map['description'].str.contains('Expired|Hospice', case=False, na=False)\n",
    "    ]['id'].tolist()\n",
    "\n",
    "    before_filter = len(df)\n",
    "    df = df[~df['discharge_disposition_id'].isin(expired_codes)]\n",
    "    print(f\"Removed {before_filter - len(df)} deceased/hospice encounters.\")\n",
    "\n",
    "    # 6. Deduplication (Exact Row Matches)\n",
    "    before_dedup = len(df)\n",
    "    df = df.drop_duplicates()\n",
    "    print(f\"Removed {before_dedup - len(df)} exact duplicate rows.\")\n",
    "\n",
    "    # 7. Stabilize Administrative Categorical IDs\n",
    "    categorical_ids = [\n",
    "        'admission_type_id',\n",
    "        'discharge_disposition_id',\n",
    "        'admission_source_id'\n",
    "    ]\n",
    "\n",
    "    for col in categorical_ids:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(str)\n",
    "\n",
    "    print(f\"\\nPhase 1 complete. Final dataset shape: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "# EXECUTION\n",
    "DATA_PATH = \"../data/raw/diabetic_data.csv\"\n",
    "ID_MAP_PATH = \"../data/raw/IDs_mapping.csv\"\n",
    "OUTPUT_PATH = \"../data/processed/diabetic_data_phase1_clean.csv\"\n",
    "\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    raise FileNotFoundError(\"Raw dataset not found. Check path.\")\n",
    "\n",
    "# Run sanitation\n",
    "df_phase1 = load_and_sanitize_data(DATA_PATH, ID_MAP_PATH)\n",
    "\n",
    "print(\"\\n--- CLEAN DATA PREVIEW ---\")\n",
    "display(df_phase1.head())\n",
    "\n",
    "# Persist cleaned dataset\n",
    "os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)\n",
    "df_phase1.to_csv(OUTPUT_PATH, index=False)\n",
    "\n",
    "print(f\"\\n✓ Phase 1 cleaned data saved to: {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0982f26d",
   "metadata": {},
   "source": [
    "## Phase 2: Data Enrichment via Web Scraping (ICD-9)\n",
    "\n",
    "### Objective\n",
    "Translate cryptic ICD-9 primary diagnosis codes into clinically meaningful disease descriptions to improve interpretability for non-technical stakeholders.\n",
    "\n",
    "### Rationale\n",
    "\n",
    "The `diag_1` column contains ICD-9 diagnosis codes (e.g., `428`, `250.02`) that are meaningful to clinicians but opaque to decision-makers.\n",
    "Rather than scraping the full ICD-9 catalog, only the **top 20 most frequent diagnoses** are enriched to balance interpretability, efficiency, and ethical scraping practices.\n",
    "\n",
    "### Methodology\n",
    "\n",
    "1. **Target Selection**\n",
    "   - Identify the top 20 most frequent `diag_1` codes.\n",
    "\n",
    "2. **Web Scraping**\n",
    "   - Use `icd9.chrisendres.com` as a public ICD-9 lookup resource.\n",
    "   - Normalize integer codes to 3-digit format (e.g., `38 → 038`).\n",
    "   - Preserve decimal codes without modification (e.g., `250.02`).\n",
    "   - Validate scraped results to avoid incorrect mappings.\n",
    "   - Introduce a 1-second delay between requests.\n",
    "\n",
    "3. **Integration**\n",
    "   - Create a new column `Primary_Diagnosis_Desc`.\n",
    "   - Codes outside the top 20 are labeled as `\"Not in Top 20\"`.\n",
    "\n",
    "The enriched dataset is persisted as a new Phase 2 artifact to preserve reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2362ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- STARTING PHASE 2: ICD-9 DATA ENRICHMENT ---\")\n",
    "\n",
    "# Helper: Fetch ICD-9 Description (Validated)\n",
    "def fetch_icd9_description(icd_code):\n",
    "    \"\"\"\n",
    "    Fetch ICD-9 long description from icd9.chrisendres.com.\n",
    "    Returns a validated disease description or a failure label.\n",
    "    \"\"\"\n",
    "\n",
    "    BASE_URL = \"http://icd9.chrisendres.com/index.php\"\n",
    "    params = {\n",
    "        \"srchtype\": \"diseases\",\n",
    "        \"srchtext\": icd_code,\n",
    "        \"Submit\": \"Search\",\n",
    "        \"action\": \"search\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(\n",
    "            BASE_URL,\n",
    "            params=params,\n",
    "            headers={\"User-Agent\": \"Mozilla/5.0\"},\n",
    "            timeout=10\n",
    "        )\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            return \"Lookup Failed\"\n",
    "\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        result_div = soup.find(\"div\", class_=\"dlvl\")\n",
    "\n",
    "        if not result_div:\n",
    "            return \"Description Not Found\"\n",
    "\n",
    "        text = result_div.text.strip()\n",
    "        parts = text.split(\" \", 1)\n",
    "\n",
    "        # Validate that returned ICD code matches the query\n",
    "        if len(parts) == 2 and parts[0].replace(\".\", \"\") == icd_code.replace(\".\", \"\"):\n",
    "            return parts[1]\n",
    "\n",
    "        return \"Description Mismatch\"\n",
    "\n",
    "    except Exception:\n",
    "        return \"Lookup Error\"\n",
    "\n",
    "# Main Enrichment Function\n",
    "def enrich_primary_diagnosis(df, top_n=20):\n",
    "    \"\"\"\n",
    "    Enrich top N ICD-9 primary diagnosis codes with scraped descriptions.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"\\nIdentifying top {top_n} primary diagnosis codes...\")\n",
    "    top_codes = df[\"diag_1\"].value_counts().head(top_n).index.tolist()\n",
    "\n",
    "    icd_mapping = {}\n",
    "\n",
    "    for code in top_codes:\n",
    "\n",
    "        if pd.isna(code):\n",
    "            icd_mapping[code] = \"Administrative / Missing\"\n",
    "            continue\n",
    "\n",
    "        code_str = str(code)\n",
    "\n",
    "        # Normalize ICD-9 format:\n",
    "        # - Integer codes → zero-padded to 3 digits (e.g., 38 → 038)\n",
    "        # - Decimal codes → left unchanged (e.g., 250.02)\n",
    "        if code_str.isdigit():\n",
    "            search_code = code_str.zfill(3)\n",
    "        else:\n",
    "            search_code = code_str\n",
    "\n",
    "        description = fetch_icd9_description(search_code)\n",
    "        icd_mapping[code] = description\n",
    "\n",
    "        print(f\"Scraped ICD-9 {search_code} → {description}\")\n",
    "\n",
    "        # Ethical scraping delay\n",
    "        time.sleep(1)\n",
    "\n",
    "    # Map descriptions to full dataset\n",
    "    df[\"Primary_Diagnosis_Desc\"] = (\n",
    "        df[\"diag_1\"]\n",
    "        .map(icd_mapping)\n",
    "        .fillna(\"Not in Top 20\")\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "# EXECUTION\n",
    "PHASE1_PATH = \"../data/processed/diabetic_data_phase1_clean.csv\"\n",
    "PHASE2_PATH = \"../data/processed/diabetic_data_phase2_enriched.csv\"\n",
    "\n",
    "if not os.path.exists(PHASE1_PATH):\n",
    "    raise FileNotFoundError(\"Phase 1 dataset not found. Run Phase 1 first.\")\n",
    "\n",
    "df = pd.read_csv(PHASE1_PATH)\n",
    "\n",
    "df = enrich_primary_diagnosis(df, top_n=20)\n",
    "\n",
    "print(\"\\n--- ENRICHED DIAGNOSIS PREVIEW ---\")\n",
    "display(df[[\"diag_1\", \"Primary_Diagnosis_Desc\"]].head(15))\n",
    "\n",
    "# Persist Phase 2 output\n",
    "df.to_csv(PHASE2_PATH, index=False)\n",
    "print(f\"\\n✓ Phase 2 complete. Enriched data saved to: {PHASE2_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4d397f",
   "metadata": {},
   "source": [
    "## Phase 3: Exploratory Data Analysis (EDA)\n",
    "\n",
    "### Objective\n",
    "To uncover patterns, disparities, and operational signals associated with hospital readmissions\n",
    "before proceeding to feature engineering or modeling.\n",
    "\n",
    "### Why EDA Matters in Clinical Analytics\n",
    "Clinical datasets often encode severity, care quality, and systemic bias indirectly.\n",
    "Exploratory analysis helps validate assumptions, detect class imbalance, and identify\n",
    "high-risk subgroups that influence downstream model behavior.\n",
    "\n",
    "### 1. Readmission Landscape\n",
    "The target variable (`readmitted`) is analyzed to assess class imbalance.\n",
    "Patients readmitted within 30 days (`<30`) represent the HRRP penalty group\n",
    "and typically form a minority class, which has implications for model evaluation\n",
    "(e.g., accuracy is insufficient; recall and precision become more important).\n",
    "\n",
    "### 2. Demographic Profiling\n",
    "- **Age Distribution** reveals whether diabetes-related hospitalizations are concentrated\n",
    "  among older patients.\n",
    "- **Race × Gender Analysis** evaluates intersectional disparities in readmission risk,\n",
    "  highlighting potential inequities in care outcomes.\n",
    "\n",
    "### 3. Medication Efficacy Analysis\n",
    "- Patients are categorized into **Insulin**, **Oral Medication**, or **No Medication** groups.\n",
    "  Insulin usage is treated as a proxy for disease severity.\n",
    "- Medication changes during admission are analyzed as a signal of clinical instability,\n",
    "  which may correlate with higher readmission risk.\n",
    "\n",
    "### 4. Operational Metrics\n",
    "- Length of stay and lab utilization are examined for correlation with readmission.\n",
    "- A correlation heatmap identifies multicollinearity among clinical workload indicators.\n",
    "- Discharge disposition is analyzed to compare outcomes for patients discharged\n",
    "  to **Home** versus **Skilled Nursing Facilities (SNF)**.\n",
    "\n",
    "All visual outputs are saved as static artifacts to ensure reproducibility and auditability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd012d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- STARTING PHASE 3: EXPLORATORY DATA ANALYSIS (EDA) ---\")\n",
    "\n",
    "# Global Visualization Settings\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "\n",
    "# Output directory for figures\n",
    "REPORTS_DIR = \"../reports\"\n",
    "os.makedirs(REPORTS_DIR, exist_ok=True)\n",
    "\n",
    "def save_and_show(filename):\n",
    "    \"\"\"Save current figure to reports directory and display it.\"\"\"\n",
    "    path = os.path.join(REPORTS_DIR, filename)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "# Load Enriched Dataset\n",
    "DATA_PATH = \"../data/processed/diabetic_data_phase2_enriched.csv\"\n",
    "\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    raise FileNotFoundError(\"Phase 2 dataset not found. Run Phase 1 and Phase 2 first.\")\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(f\"Dataset loaded successfully: {df.shape}\")\n",
    "\n",
    "# Binary target: 30-day readmission\n",
    "df[\"target\"] = (df[\"readmitted\"] == \"<30\").astype(int)\n",
    "\n",
    "# Safely coerce discharge disposition\n",
    "df[\"discharge_disposition_id\"] = pd.to_numeric(\n",
    "    df[\"discharge_disposition_id\"], errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# 1. Readmission Landscape\n",
    "print(\"--- 1. Readmission Landscape ---\")\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "ax = sns.countplot(\n",
    "    x=\"readmitted\",\n",
    "    data=df,\n",
    "    order=[\"NO\", \">30\", \"<30\"],\n",
    "    palette=\"viridis\"\n",
    ")\n",
    "\n",
    "plt.title(\"Distribution of Readmission Classes\")\n",
    "plt.xlabel(\"Readmission Status\")\n",
    "plt.ylabel(\"Patient Count\")\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(\n",
    "        f\"{p.get_height() / len(df) * 100:.1f}%\",\n",
    "        (p.get_x() + p.get_width() / 2, p.get_height()),\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\"\n",
    "    )\n",
    "\n",
    "print(\"--- 1.1 Readmission Distribution ---\")\n",
    "save_and_show(\"1_readmission_distribution.png\")\n",
    "\n",
    "# 2. Demographic Profiling\n",
    "print(\"--- 2. Demographic Profiling ---\")\n",
    "\n",
    "plt.figure()\n",
    "sns.countplot(x=\"age\", data=df, palette=\"coolwarm\")\n",
    "plt.title(\"Age Distribution of Diabetic Patients\")\n",
    "plt.xticks(rotation=45)\n",
    "print(\"--- 2.1 Age Distribution ---\")\n",
    "save_and_show(\"2_age_distribution.png\")\n",
    "\n",
    "plt.figure()\n",
    "sns.barplot(\n",
    "    x=\"race\",\n",
    "    y=\"target\",\n",
    "    hue=\"gender\",\n",
    "    data=df,\n",
    "    errorbar=None,\n",
    "    palette=\"muted\"\n",
    ")\n",
    "plt.title(\"30-Day Readmission Rate by Race and Gender\")\n",
    "plt.ylabel(\"Readmission Rate (<30)\")\n",
    "plt.xticks(rotation=45)\n",
    "print(\"--- 2.2 Readmission Rate by Race and Gender ---\")\n",
    "save_and_show(\"3_readmission_by_race_gender.png\")\n",
    "\n",
    "# 3. Medication Efficacy Analysis\n",
    "print(\"--- 3. Medication Efficacy Analysis ---\")\n",
    "\n",
    "oral_meds = [\n",
    "    'metformin','repaglinide','nateglinide','chlorpropamide','glimepiride',\n",
    "    'acetohexamide','glipizide','glyburide','tolbutamide','pioglitazone',\n",
    "    'rosiglitazone','acarbose','miglitol','troglitazone','tolazamide',\n",
    "    'examide','citoglipton','glyburide-metformin','glipizide-metformin',\n",
    "    'glimepiride-pioglitazone','metformin-rosiglitazone','metformin-pioglitazone'\n",
    "]\n",
    "\n",
    "def classify_medication(row):\n",
    "    if row[\"insulin\"] != \"No\":\n",
    "        return \"Insulin\"\n",
    "    if any(row[med] != \"No\" for med in oral_meds):\n",
    "        return \"Oral Only\"\n",
    "    return \"No Medication\"\n",
    "\n",
    "df[\"med_status\"] = df.apply(classify_medication, axis=1)\n",
    "\n",
    "plt.figure()\n",
    "sns.barplot(\n",
    "    x=\"med_status\",\n",
    "    y=\"target\",\n",
    "    data=df,\n",
    "    errorbar=None,\n",
    "    palette=\"Set2\"\n",
    ")\n",
    "plt.title(\"Readmission Risk by Medication Type\")\n",
    "plt.ylabel(\"Readmission Rate (<30)\")\n",
    "print(\"--- 3.1 Readmission Risk by Medication Type ---\")\n",
    "save_and_show(\"4_readmission_by_medication_type.png\")\n",
    "\n",
    "plt.figure()\n",
    "sns.barplot(\n",
    "    x=\"change\",\n",
    "    y=\"target\",\n",
    "    data=df,\n",
    "    errorbar=None,\n",
    "    palette=\"pastel\"\n",
    ")\n",
    "plt.title(\"Readmission Risk by Medication Change\")\n",
    "plt.ylabel(\"Readmission Rate (<30)\")\n",
    "print(\"--- 3.2 Readmission Risk by Medication Change ---\")\n",
    "save_and_show(\"5_readmission_by_medication_change.png\")\n",
    "\n",
    "# 4. Operational Metrics\n",
    "print(\"--- 4. Operational Metrics ---\")\n",
    "\n",
    "plt.figure()\n",
    "plt.hexbin(\n",
    "    df[\"time_in_hospital\"],\n",
    "    df[\"num_lab_procedures\"],\n",
    "    gridsize=25,\n",
    "    cmap=\"Blues\"\n",
    ")\n",
    "plt.colorbar(label=\"Patient Density\")\n",
    "plt.xlabel(\"Time in Hospital (Days)\")\n",
    "plt.ylabel(\"Number of Lab Procedures\")\n",
    "plt.title(\"Hospital Stay Length vs Lab Utilization\")\n",
    "print(\"--- 4.1 Hospital Stay vs Lab Utilization ---\")\n",
    "save_and_show(\"6_stay_vs_lab_utilization.png\")\n",
    "\n",
    "num_cols = [\n",
    "    \"time_in_hospital\",\n",
    "    \"num_lab_procedures\",\n",
    "    \"num_procedures\",\n",
    "    \"num_medications\",\n",
    "    \"number_diagnoses\"\n",
    "]\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(\n",
    "    df[num_cols].corr(),\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"coolwarm\"\n",
    ")\n",
    "plt.title(\"Correlation Heatmap of Clinical Metrics\")\n",
    "print(\"--- 4.2 Clinical Metrics Correlation ---\")\n",
    "save_and_show(\"7_clinical_metrics_correlation.png\")\n",
    "\n",
    "plt.figure()\n",
    "sns.boxplot(\n",
    "    x=\"readmitted\",\n",
    "    y=\"time_in_hospital\",\n",
    "    data=df,\n",
    "    order=[\"NO\", \">30\", \"<30\"],\n",
    "    palette=\"Set3\"\n",
    ")\n",
    "plt.title(\"Length of Stay by Readmission Outcome\")\n",
    "print(\"--- 4.3 Length of Stay by Readmission Outcome ---\")\n",
    "save_and_show(\"8_los_by_readmission.png\")\n",
    "\n",
    "subset = df[df[\"discharge_disposition_id\"].isin([1, 3])].copy()\n",
    "subset[\"discharge_location\"] = subset[\"discharge_disposition_id\"].map({\n",
    "    1: \"Home\",\n",
    "    3: \"Skilled Nursing Facility\"\n",
    "})\n",
    "\n",
    "plt.figure()\n",
    "sns.barplot(\n",
    "    x=\"discharge_location\",\n",
    "    y=\"target\",\n",
    "    data=subset,\n",
    "    errorbar=None,\n",
    "    palette=\"autumn\"\n",
    ")\n",
    "plt.title(\"Readmission Rate: Home vs Skilled Nursing Facility\")\n",
    "plt.ylabel(\"Readmission Rate (<30)\")\n",
    "print(\"--- 4.4 Readmission by Discharge Location ---\")\n",
    "save_and_show(\"9_readmission_by_discharge_location.png\")\n",
    "\n",
    "print(\"\\n✓ Phase 3 complete. All EDA figures saved to the reports/ directory.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1e696d",
   "metadata": {},
   "source": [
    "## Phase 4: Feature Engineering — Vitality Complexity Index (VCI)\n",
    "\n",
    "### Objective\n",
    "To translate clinical intuition into a programmable risk stratification algorithm that\n",
    "identifies patients at high risk of 30-day readmission.\n",
    "\n",
    "### Clinical Motivation\n",
    "Nursing leadership requires a **simple, interpretable score** to flag complex patients\n",
    "during hospitalization. Rather than deploying a black-box model, we implement a\n",
    "simplified variant of the **LACE Index**, a clinically validated readmission risk tool.\n",
    "\n",
    "### VCI Components\n",
    "The Vitality Complexity Index (VCI) combines four dimensions of patient complexity:\n",
    "\n",
    "- **L — Length of Stay:** Proxy for illness severity and care intensity  \n",
    "- **A — Acuity of Admission:** Emergency and trauma admissions signal instability  \n",
    "- **C — Comorbidity Burden:** Approximated using number of diagnoses  \n",
    "- **E — Emergency Visits:** Prior utilization reflects chronic instability  \n",
    "\n",
    "Each component is scored independently and summed to form `VCI_Score`.\n",
    "- **Calculation:** VCI_Score = L + A + C + E\n",
    "\n",
    "### Risk Stratification\n",
    "Patients are categorized into three clinically meaningful risk tiers:\n",
    "\n",
    "- **Low Risk:** VCI < 7  \n",
    "- **Medium Risk:** VCI 7–10  \n",
    "- **High Risk:** VCI > 10  \n",
    "\n",
    "The effectiveness of the index is validated by comparing **30-day readmission rates**\n",
    "across these risk groups. A monotonic increase supports the clinical usefulness of the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59790964",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- STARTING PHASE 4: VITALITY COMPLEXITY INDEX (VCI) ---\")\n",
    "\n",
    "# Configuration\n",
    "DATA_PATH = \"../data/processed/diabetic_data_phase2_enriched.csv\"\n",
    "REPORTS_DIR = \"../reports\"\n",
    "os.makedirs(REPORTS_DIR, exist_ok=True)\n",
    "\n",
    "# Load Data (Reproducibility Guaranteed)\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    raise FileNotFoundError(\"Phase 2 dataset not found. Run Phases 1–3 first.\")\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(f\"Dataset loaded: {df.shape}\")\n",
    "\n",
    "# Ensure numeric types for scoring\n",
    "df[\"admission_type_id\"] = pd.to_numeric(df[\"admission_type_id\"], errors=\"coerce\")\n",
    "df[\"number_emergency\"] = pd.to_numeric(df[\"number_emergency\"], errors=\"coerce\")\n",
    "\n",
    "# VCI Scoring Functions (Modular & Testable)\n",
    "def calculate_L_points(days):\n",
    "    \"\"\"L — Length of Stay\"\"\"\n",
    "    if days < 1:\n",
    "        return 0\n",
    "    elif 1 <= days <= 4:\n",
    "        return 1\n",
    "    elif 5 <= days <= 13:\n",
    "        return 4\n",
    "    else:\n",
    "        return 7  # >= 14 days\n",
    "\n",
    "def calculate_A_points(admission_id):\n",
    "    \"\"\"A — Acuity of Admission\"\"\"\n",
    "    return 3 if admission_id in [1, 7] else 0\n",
    "\n",
    "def calculate_C_points(num_diagnoses):\n",
    "    \"\"\"C — Comorbidity Burden\"\"\"\n",
    "    if num_diagnoses < 4:\n",
    "        return 0\n",
    "    elif 4 <= num_diagnoses <= 7:\n",
    "        return 3\n",
    "    else:\n",
    "        return 5  # >= 8 diagnoses\n",
    "\n",
    "def calculate_E_points(num_emergency):\n",
    "    \"\"\"E — Emergency Visit Intensity\"\"\"\n",
    "    if num_emergency == 0:\n",
    "        return 0\n",
    "    elif 1 <= num_emergency <= 4:\n",
    "        return 3\n",
    "    else:\n",
    "        return 5  # > 4 visits\n",
    "\n",
    "def assign_risk_category(score):\n",
    "    \"\"\"Map VCI score to clinical risk tier\"\"\"\n",
    "    if score < 7:\n",
    "        return \"Low Risk\"\n",
    "    elif 7 <= score <= 10:\n",
    "        return \"Medium Risk\"\n",
    "    else:\n",
    "        return \"High Risk\"\n",
    "\n",
    "# Apply VCI Framework\n",
    "print(\"Calculating VCI components...\")\n",
    "\n",
    "df[\"L_points\"] = df[\"time_in_hospital\"].apply(calculate_L_points)\n",
    "df[\"A_points\"] = df[\"admission_type_id\"].apply(calculate_A_points)\n",
    "df[\"C_points\"] = df[\"number_diagnoses\"].apply(calculate_C_points)\n",
    "df[\"E_points\"] = df[\"number_emergency\"].apply(calculate_E_points)\n",
    "\n",
    "df[\"VCI_Score\"] = (\n",
    "    df[\"L_points\"]\n",
    "    + df[\"A_points\"]\n",
    "    + df[\"C_points\"]\n",
    "    + df[\"E_points\"]\n",
    ")\n",
    "\n",
    "df[\"VCI_Risk_Category\"] = df[\"VCI_Score\"].apply(assign_risk_category)\n",
    "\n",
    "# Distribution Check\n",
    "print(\"\\nVCI Risk Category Distribution:\")\n",
    "print(df[\"VCI_Risk_Category\"].value_counts(normalize=True).round(3))\n",
    "\n",
    "# Validation: Readmission Rate by Risk Tier\n",
    "validation = (\n",
    "    df.groupby(\"VCI_Risk_Category\")[\"readmitted\"]\n",
    "      .value_counts(normalize=True)\n",
    "      .unstack()\n",
    ")\n",
    "\n",
    "validation[\"Readmission Rate (<30)\"] = validation[\"<30\"] * 100\n",
    "validation = validation.loc[[\"Low Risk\", \"Medium Risk\", \"High Risk\"]]\n",
    "\n",
    "# Visualization (Saved Artifact)\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "sns.barplot(\n",
    "    x=validation.index,\n",
    "    y=validation[\"Readmission Rate (<30)\"],\n",
    "    palette=[\"#4CAF50\", \"#FF9800\", \"#F44336\"],\n",
    "    errorbar=None\n",
    ")\n",
    "\n",
    "plt.title(\"Validation of VCI: 30-Day Readmission Rate by Risk Group\")\n",
    "plt.ylabel(\"Readmission Rate (%)\")\n",
    "plt.xlabel(\"VCI Risk Category\")\n",
    "\n",
    "for i, v in enumerate(validation[\"Readmission Rate (<30)\"]):\n",
    "    plt.text(i, v + 0.3, f\"{v:.1f}%\", ha=\"center\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(REPORTS_DIR, \"10_vci_readmission_validation.png\"), dpi=300)\n",
    "print(\"--- Validation of VCI: 30-Day Readmission Rate by Risk Group ---\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Phase 4 complete. VCI validated and visualization saved to reports/.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
