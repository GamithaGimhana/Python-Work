{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d825961",
   "metadata": {},
   "source": [
    "## Phase 1: Data Ingestion & Clinical Sanitation\n",
    "\n",
    "Clinical Context & Rationale\n",
    "\n",
    "Raw healthcare data is designed for billing, not analytics. It often contains artifacts that can severely bias predictive modeling. Before we can calculate risk scores, we must sanitize the dataset to ensure clinical validity.\n",
    "\n",
    "Key Actions & Justifications:\n",
    "\n",
    "1. Removing \"Weight\": This variable has >90% missingness. Imputing it would introduce massive artificial noise, so we remove it entirely to preserve data integrity.\n",
    "\n",
    "2. Excluding Deceased Patients: Patients who expired during their stay cannot be readmitted. Including them would artificially lower the readmission rate and confuse the model target.\n",
    "\n",
    "3. Standardizing Identifiers: Numerical IDs (like admission_type_id) are categorical labels, not mathematical values. We treat them as strings/categories to prevent the model from misinterpreting them as quantities.\n",
    "\n",
    "4. Exporting Clean Data: We save the filtered dataset to a new file (diabetic_data_clean.csv) so subsequent phases can load reliable data directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dccd45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- IMPORTING LIBRARIES ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- IMPORTING LIBRARIES ---\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Configuration to display all columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6f318ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STARTING PHASE 1 ---\n",
      "Error: '../data/diabetic_data.csv' not found. Please ensure the file is in the notebook directory.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- STARTING PHASE 1 ---\")\n",
    "\n",
    "def load_and_sanitize_data(filepath, id_map_path, output_path):\n",
    "    \"\"\"\n",
    "    Loads raw data, handles missing values, removes invalid rows (deceased),\n",
    "    drops structurally missing columns, AND saves the clean file.\n",
    "    \"\"\"\n",
    "    # 1. Load Data with standardized missing values\n",
    "    print(f\"Loading dataset from: {filepath}\")\n",
    "    df = pd.read_csv(filepath, na_values=\"?\")\n",
    "    \n",
    "    # 2. Drop 'weight' due to >90% missingness (Clinical decision)\n",
    "    if 'weight' in df.columns:\n",
    "        df = df.drop(columns=['weight'])\n",
    "        print(\"- Dropped 'weight' column (>90% missing).\")\n",
    "\n",
    "    # 3. Load ID Mapping to identify discharge codes\n",
    "    # We define this inside a try-block in case the map file is messy\n",
    "    try:\n",
    "        id_map = pd.read_csv(id_map_path, header=None, names=[\"id\", \"description\"])\n",
    "        \n",
    "        # Extract Discharge Disposition block from the mapping file\n",
    "        # The file is semi-structured, so we find the specific section\n",
    "        start = id_map[id_map[\"id\"] == \"discharge_disposition_id\"].index[0] + 1\n",
    "        end = id_map[id_map[\"id\"] == \"admission_source_id\"].index[0]\n",
    "        discharge_map = id_map.iloc[start:end].copy()\n",
    "        \n",
    "        # 4. Identify Deceased Codes (Expired + Hospice)\n",
    "        # We ensure IDs are numeric for matching\n",
    "        discharge_map[\"id\"] = pd.to_numeric(discharge_map[\"id\"], errors='coerce')\n",
    "        \n",
    "        # Search for descriptions containing \"Expired\" or \"Hospice\" to be thorough\n",
    "        # This covers IDs 11, 19, 20, 21 (Expired) and often 13, 14 (Hospice)\n",
    "        expired_mask = discharge_map[\"description\"].str.contains(\"Expired|Hospice\", case=False, na=False)\n",
    "        expired_codes = discharge_map[expired_mask][\"id\"].tolist()\n",
    "        \n",
    "        print(f\"  > Identified Deceased/Expired Codes to drop: {expired_codes}\")\n",
    "        \n",
    "        # Filter dataset\n",
    "        initial_count = len(df)\n",
    "        df = df[~df['discharge_disposition_id'].isin(expired_codes)]\n",
    "        print(f\"- Removed {initial_count - len(df)} deceased patient records.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not filter deceased patients. Error in ID mapping: {e}\")\n",
    "\n",
    "    # 5. Remove exact duplicates (System errors)\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    # 6. Convert categorical IDs to strings (prevent mathematical usage)\n",
    "    # This prevents the model from thinking ID 2 is \"double\" ID 1.\n",
    "    cat_cols = ['admission_type_id', 'discharge_disposition_id', 'admission_source_id']\n",
    "    for col in cat_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(str)\n",
    "        \n",
    "    print(f\"Sanitation Complete. Final Shape: {df.shape}\")\n",
    "    \n",
    "    # 7. EXPORT TO NEW FILE\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"✓ Saved clean data to: {output_path}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# EXECUTION PHASE 1\n",
    "input_csv = \"../data/diabetic_data.csv\"\n",
    "mapping_csv = \"../data/IDs_mapping.csv\"\n",
    "output_csv = \"../data/diabetic_data_clean.csv\"\n",
    "\n",
    "if os.path.exists(input_csv):\n",
    "    df_clean = load_and_sanitize_data(\n",
    "        input_csv, \n",
    "        mapping_csv, \n",
    "        output_csv\n",
    "    )\n",
    "    # Display first few rows to confirm load\n",
    "    print(\"\\nPreview of Clean Data:\")\n",
    "    print(df_clean.head())\n",
    "else:\n",
    "    print(f\"Error: '{input_csv}' not found. Please ensure the file is in the notebook directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2593046f",
   "metadata": {},
   "source": [
    "## Phase 2: Clinical Enrichment (ICD-9 Scraper)\n",
    "\n",
    "Why we need this\n",
    "\n",
    "The dataset uses ICD-9 codes (e.g., 428, 250.01) to represent diagnoses. These numbers are meaningless to non-clinical stakeholders.\n",
    "\n",
    "To make our analysis interpretable for VHN administration, we scrape the clinical text descriptions for the most frequent diagnoses. This allows us to say \"Heart Failure\" instead of \"Code 428\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeaecf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- STARTING PHASE 2 ---\")\n",
    "\n",
    "def fetch_icd9_description(code):\n",
    "    \"\"\"\n",
    "    Scrapes icd9.chrisendres.com to get the text description of a code.\n",
    "    Includes error handling and delays to be polite to the server.\n",
    "    \"\"\"\n",
    "    base_url = \"http://icd9.chrisendres.com/index.php\"\n",
    "    params = {\n",
    "        'srchtype': 'diseases',\n",
    "        'srchtext': code,\n",
    "        'Submit': 'Search',\n",
    "        'action': 'search'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(base_url, params=params, headers={\"User-Agent\": \"Chrome/120.0.0.0\"})\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "            # The site puts descriptions in a div with class 'dlvl'\n",
    "            div = soup.find('div', class_='dlvl')\n",
    "            if div:\n",
    "                # Text usually looks like \"038 Septicemia\", so we split it\n",
    "                text = div.text.strip()\n",
    "                parts = text.split(' ', 1)\n",
    "                \n",
    "                # Check match. Note: The website might return \"038\" even if we searched \"38\" or \"038\"\n",
    "                # So we check if the returned code (parts[0]) matches our input code \n",
    "                # OR if our input code matches the returned code without the leading zero.\n",
    "                returned_code = parts[0]\n",
    "                if len(parts) > 1 and (returned_code == str(code) or returned_code == str(code).zfill(3)):\n",
    "                    return parts[1]\n",
    "    except Exception as e:\n",
    "        return f\"Lookup Failed: {e}\"\n",
    "    \n",
    "    return \"Description Not Found\"\n",
    "\n",
    "def enrich_diagnoses(df, top_n=20):\n",
    "    \"\"\"\n",
    "    Identifies top N codes, scrapes descriptions, and maps them.\n",
    "    Codes outside the top N are labeled 'Not in Top 20'.\n",
    "    \"\"\"\n",
    "    # Identify top N most frequent diagnosis codes\n",
    "    top_codes = df['diag_1'].value_counts().head(top_n).index.tolist()\n",
    "    print(f\"Scraping descriptions for top {top_n} diagnoses...\")\n",
    "    \n",
    "    mapping = {}\n",
    "    for code in top_codes:\n",
    "        code_str = str(code)\n",
    "        \n",
    "        # Check if code is numeric or special string before scraping\n",
    "        if code_str != '?' and code_str != 'None':\n",
    "            # Check length and pad if necessary for the search\n",
    "            search_term = code_str\n",
    "            if len(code_str) < 3 and code_str.isdigit():\n",
    "                search_term = code_str.zfill(3) # \"38\" -> \"038\"\n",
    "             \n",
    "            desc = fetch_icd9_description(search_term)\n",
    "             \n",
    "            # If \"Description Not Found\" with padded code, try original just in case\n",
    "            if desc == \"Description Not Found\" and search_term != code_str:\n",
    "                desc = fetch_icd9_description(code_str)\n",
    "\n",
    "            mapping[code_str] = desc\n",
    "            print(f\"Code {code_str} (searched '{search_term}'): {desc}\")\n",
    "            time.sleep(1) # Polite delay\n",
    "        else:\n",
    "            mapping[code_str] = \"Administrative/Other\"\n",
    "            print(f\"Code {code_str}: Administrative/Other\")\n",
    "        \n",
    "    # Apply mapping:\n",
    "    # 1. Map the known codes\n",
    "    # 2. Fill everything else (NaN) with \"Not in Top 20\"\n",
    "    df['Primary_Diagnosis_Desc'] = df['diag_1'].map(mapping).fillna(\"Not in Top 20\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# EXECUTION PHASE 2\n",
    "# Check for the clean file in the current directory\n",
    "if os.path.exists(\"../data/diabetic_data_clean.csv\"):\n",
    "    df_clean = pd.read_csv(\"../data/diabetic_data_clean.csv\")\n",
    "    \n",
    "    # Run enrichment with Top 20\n",
    "    df_clean = enrich_diagnoses(df_clean, top_n=20)\n",
    "    \n",
    "    # Show results\n",
    "    print(\"\\nSample of Enriched Diagnoses:\")\n",
    "    print(df_clean[['diag_1', 'Primary_Diagnosis_Desc']].head(10))\n",
    "    \n",
    "    # --- CRITICAL STEP: SAVE THE DATA ---\n",
    "    df_clean.to_csv(\"../data/diabetic_data_clean.csv\", index=False)\n",
    "    print(\"\\n✓ Saved enriched data to 'diabetic_data_clean.csv'\")\n",
    "    \n",
    "else:\n",
    "    print(\"Clean data file not found. Run Phase 1 first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f635a4bb",
   "metadata": {},
   "source": [
    "## Phase 3: Exploratory Data Analysis (EDA)\n",
    "\n",
    "Objective\n",
    "\n",
    "We dig into the dataset to uncover the \"shape\" of the data and identifying the drivers of readmission. This phase moves beyond data cleaning to insight generation.\n",
    "\n",
    "Why we do this\n",
    "\n",
    "1. Imbalance Detection: If the target class (<30) is rare, our future models might ignore it. We need to quantify this imbalance.\n",
    "2. Demographic Disparities: Healthcare outcomes often vary by age, race, and gender. Identifying these disparities is an ethical and clinical necessity.\n",
    "3. Medication & Operations: Understanding how treatment complexity (Insulin usage, polypharmacy) and hospital operations (Time in hospital, discharge location) impact readmission helps operationalize the findings for VHN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa156f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- STARTING PHASE 3 ---\")\n",
    "\n",
    "# Set visual style for professional charts\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "# Load the clean data\n",
    "# Note: Using the specific path requested\n",
    "file_path = \"../data/diabetic_data_clean.csv\"\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"Data Loaded. Shape: {df.shape}\")\n",
    "else:\n",
    "    print(f\"Error: Clean data file not found at {file_path}. Please run Phase 1 & 2 or check the path.\")\n",
    "\n",
    "# --- HELPER FUNCTIONS ---\n",
    "\n",
    "def plot_readmission_landscape(df):\n",
    "    \"\"\"\n",
    "    1. The Readmission Landscape: Analyzes the target variable distribution.\n",
    "    Why: To identify class imbalance which affects model choice and metric selection.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    \n",
    "    # Calculate percentages\n",
    "    counts = df['readmitted'].value_counts(normalize=True) * 100\n",
    "    \n",
    "    ax = sns.countplot(x='readmitted', data=df, order=['NO', '>30', '<30'], palette='viridis')\n",
    "    plt.title('Distribution of Readmission Classes', fontsize=14)\n",
    "    plt.ylabel('Patient Count')\n",
    "    plt.xlabel('Readmission Status')\n",
    "    \n",
    "    # Add percentage labels\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(f'{p.get_height() / len(df) * 100:.1f}%', \n",
    "                    (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                    ha = 'center', va = 'center', xytext = (0, 5), textcoords = 'offset points')\n",
    "    \n",
    "    plt.show()\n",
    "    print(f\"Insight: The target class (<30 days) represents {counts.get('<30', 0):.1f}% of the data.\")\n",
    "    print(\"This indicates a moderate class imbalance that may require stratification or resampling later.\")\n",
    "    \n",
    "    print(\"\\nDetailed Readmission Rates:\")\n",
    "    print(df['readmitted'].value_counts(normalize=True) * 100)\n",
    "\n",
    "def analyze_demographics(df):\n",
    "    \"\"\"\n",
    "    2. Demographic Profiling: Age, Race, and Gender analysis.\n",
    "    Why: To detect if specific subgroups are disproportionately affecting readmission rates.\n",
    "    \"\"\"\n",
    "    # Age Distribution\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    sns.countplot(x='age', data=df, palette='coolwarm')\n",
    "    plt.title('Age Distribution of Patient Cohort')\n",
    "    plt.show()\n",
    "\n",
    "    # Race & Gender Stratification\n",
    "    # We create a pivot table to see the rate of <30 readmissions\n",
    "    df['target'] = (df['readmitted'] == '<30').astype(int)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='race', y='target', hue='gender', data=df, ci=None, palette='muted')\n",
    "    plt.title('30-Day Readmission Rate by Race and Gender')\n",
    "    plt.ylabel('Readmission Rate (<30)')\n",
    "    plt.legend(title='Gender', loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "    # Textual Insight\n",
    "    rates = df.groupby(['race', 'gender'])['target'].mean() * 100\n",
    "    print(\"Readmission Rates (<30) Summary:\")\n",
    "    print(rates)\n",
    "\n",
    "def analyze_medication_efficacy(df):\n",
    "    \"\"\"\n",
    "    3. Medication Efficacy: Insulin vs Oral vs No Meds.\n",
    "    Why: Insulin usage often signals advanced disease progression (severity).\n",
    "    \"\"\"\n",
    "    # Define Logic: \n",
    "    # If Insulin != No -> 'Insulin' (High Severity)\n",
    "    # Else If any other med != No -> 'Oral Only'\n",
    "    # Else -> 'No Meds'\n",
    "    \n",
    "    # List of 22 oral meds (excluding insulin)\n",
    "    # These represent the full list of diabetes medications recorded in the dataset\n",
    "    oral_meds = ['metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', \n",
    "                 'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide', \n",
    "                 'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone', \n",
    "                 'tolazamide', 'examide', 'citoglipton', 'glyburide-metformin', \n",
    "                 'glipizide-metformin', 'glimepiride-pioglitazone', \n",
    "                 'metformin-rosiglitazone', 'metformin-pioglitazone']\n",
    "    \n",
    "    def classify_meds(row):\n",
    "        # Priority 1: Insulin usage indicates higher severity/complexity\n",
    "        if row['insulin'] != 'No':\n",
    "            return 'Insulin (Any)'\n",
    "        \n",
    "        # Priority 2: Check if any oral med is taken\n",
    "        # We iterate through all 22 oral medication columns. \n",
    "        # If any of them are NOT 'No', the patient is on oral meds.\n",
    "        for med in oral_meds:\n",
    "            if med in row and row[med] != 'No':\n",
    "                return 'Oral Only'\n",
    "        \n",
    "        # Priority 3: Neither insulin nor oral meds\n",
    "        return 'No Medication'\n",
    "\n",
    "    df['med_status'] = df.apply(classify_meds, axis=1)\n",
    "\n",
    "    # Visualization 1: Insulin vs Oral\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.barplot(x='med_status', y='target', data=df, ci=None, palette='Set2')\n",
    "    plt.title('Readmission Risk by Medication Type')\n",
    "    plt.ylabel('Readmission Rate (<30)')\n",
    "    plt.show()\n",
    "\n",
    "    # Visualization 2: Change in Meds\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.barplot(x='change', y='target', data=df, ci=None, palette='pastel')\n",
    "    plt.title('Readmission Risk: Medication Change vs No Change')\n",
    "    plt.ylabel('Readmission Rate (<30)')\n",
    "    plt.show()\n",
    "\n",
    "def analyze_operational_metrics(df):\n",
    "    \"\"\"\n",
    "    4. Operational Metrics: Time in hospital, Lab procedures, Discharge location.\n",
    "    Why: To find operational bottlenecks or indicators of complex stays.\n",
    "    \"\"\"\n",
    "    # Scatter: Time vs Labs\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    # Using hexbin for clearer density visualization with large data\n",
    "    plt.hexbin(df['time_in_hospital'], df['num_lab_procedures'], gridsize=20, cmap='Blues')\n",
    "    plt.colorbar(label='Count')\n",
    "    plt.title('Time in Hospital vs Number of Lab Procedures')\n",
    "    plt.xlabel('Days in Hospital')\n",
    "    plt.ylabel('Num Lab Procedures')\n",
    "    plt.show()\n",
    "\n",
    "    # Correlation Heatmap\n",
    "    cols = ['time_in_hospital', 'num_lab_procedures', 'num_procedures', 'num_medications', 'number_diagnoses']\n",
    "    corr = df[cols].corr()\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "    plt.title('Correlation Heatmap of Numerical Features')\n",
    "    plt.show()\n",
    "\n",
    "    # Box Plot: Time in Hospital by Readmission\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.boxplot(x='readmitted', y='time_in_hospital', data=df, order=['NO', '>30', '<30'], palette='Set3')\n",
    "    plt.title('Length of Stay Distribution by Readmission Status')\n",
    "    plt.show()\n",
    "\n",
    "    # Discharge Disposition: Home (1) vs SNF (3)\n",
    "    # Filter for just these two common codes for clear comparison\n",
    "    subset = df[df['discharge_disposition_id'].isin(['1', '3'])].copy()\n",
    "    subset['location'] = subset['discharge_disposition_id'].map({'1': 'Home', '3': 'Skilled Nursing Facility'})\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.barplot(x='location', y='target', data=subset, ci=None, palette='autumn')\n",
    "    plt.title('Readmission Rate: Home vs Skilled Nursing Facility (SNF)')\n",
    "    plt.ylabel('Readmission Rate (<30)')\n",
    "    plt.show()\n",
    "\n",
    "# --- EXECUTION ---\n",
    "if 'df' in locals():\n",
    "    print(\"--- 1. Readmission Landscape ---\")\n",
    "    plot_readmission_landscape(df)\n",
    "    \n",
    "    print(\"\\n--- 2. Demographic Profiling ---\")\n",
    "    analyze_demographics(df)\n",
    "    \n",
    "    print(\"\\n--- 3. Medication Efficacy ---\")\n",
    "    analyze_medication_efficacy(df)\n",
    "    \n",
    "    print(\"\\n--- 4. Operational Metrics ---\")\n",
    "    analyze_operational_metrics(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b282c7",
   "metadata": {},
   "source": [
    "## Phase 4: Feature Engineering – Vitality Complexity Index (VCI)\n",
    "\n",
    "Operational GoalNursing leadership requires a simple, rule-based score to identify high-risk patients on the floor. Machine learning models are often \"black boxes\"; the VCI is designed to be transparent.\n",
    "\n",
    "Scoring Logic (The \"Why\")\n",
    "\n",
    "We calculate points based on clinical proxies for instability:\n",
    "1. L (Length of Stay): Longer stays imply complications ($>14$ days = 7 points).\n",
    "2. A (Acuity): Emergency admissions indicate an unstable start state (Emergency = 3 points).\n",
    "3. C (Comorbidity): More diagnoses suggest systemic failure ($>8$ diagnoses = 5 points).\n",
    "4. E (Emergency Visits): Frequent ED usage shows poor outpatient control ($>4$ visits = 5 points).\n",
    "\n",
    "##### Total VCI = L + A + C + E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb66118",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- STARTING PHASE 4 ---\")\n",
    "\n",
    "# --- VCI Helper Functions ---\n",
    "\n",
    "def calculate_L_points(days):\n",
    "    \"\"\"L: Length of Stay points\"\"\"\n",
    "    if days < 1: return 0\n",
    "    if 1 <= days <= 4: return 1\n",
    "    if 5 <= days <= 13: return 4\n",
    "    return 7 # >= 14 days\n",
    "\n",
    "def calculate_A_points(admission_id):\n",
    "    \"\"\"A: Acuity points (Emergency=1, Trauma=7 get points)\"\"\"\n",
    "    # Note: admission_id is string because we sanitized it in Phase 1\n",
    "    if str(admission_id) in ['1', '7']:\n",
    "        return 3\n",
    "    return 0\n",
    "\n",
    "def calculate_C_points(num_diagnoses):\n",
    "    \"\"\"C: Comorbidity Burden points\"\"\"\n",
    "    if num_diagnoses < 4: return 0\n",
    "    if 4 <= num_diagnoses <= 7: return 3\n",
    "    return 5 # >= 8 diagnoses\n",
    "\n",
    "def calculate_E_points(num_emergency):\n",
    "    \"\"\"E: Emergency Visit History points\"\"\"\n",
    "    if num_emergency == 0: return 0\n",
    "    if 1 <= num_emergency <= 4: return 3\n",
    "    return 5 # > 4 visits\n",
    "\n",
    "def assign_risk_category(score):\n",
    "    \"\"\"Categorizes VCI Score into Clinical Risk Groups\"\"\"\n",
    "    if score < 7: return \"Low Risk\"\n",
    "    if 7 <= score <= 10: return \"Medium Risk\"\n",
    "    return \"High Risk\"\n",
    "\n",
    "# --- Main Feature Engineering Function ---\n",
    "\n",
    "def apply_vci_scoring(df):\n",
    "    \"\"\"\n",
    "    Applies the VCI framework to the dataframe.\n",
    "    \"\"\"\n",
    "    print(\"Calculating Vitality Complexity Index (VCI)...\")\n",
    "    \n",
    "    # 1. Calculate Component Points\n",
    "    df['L_points'] = df['time_in_hospital'].apply(calculate_L_points)\n",
    "    df['A_points'] = df['admission_type_id'].apply(calculate_A_points)\n",
    "    df['C_points'] = df['number_diagnoses'].apply(calculate_C_points)\n",
    "    df['E_points'] = df['number_emergency'].apply(calculate_E_points)\n",
    "    \n",
    "    # 2. Sum for Total Score\n",
    "    df['VCI_Score'] = df['L_points'] + df['A_points'] + df['C_points'] + df['E_points']\n",
    "    \n",
    "    # 3. Stratify Risk\n",
    "    df['VCI_Risk_Category'] = df['VCI_Score'].apply(assign_risk_category)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# EXECUTION PHASE 4\n",
    "if 'df_clean' in locals():\n",
    "    df_final = apply_vci_scoring(df_clean)\n",
    "\n",
    "    # Validate Distribution\n",
    "    print(\"\\nRisk Category Distribution:\")\n",
    "    print(df_final['VCI_Risk_Category'].value_counts(normalize=True))\n",
    "else:\n",
    "    print(\"Dataframe not loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef9d80f",
   "metadata": {},
   "source": [
    "Validation: Does VCI actually predict readmission?\n",
    "\n",
    "To confirm the VCI is valid, we check the actual readmission rates for each group. We expect a monotonic increase (Low < Medium < High)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d52ef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_final' in locals():\n",
    "    # Calculate Readmission Rates by Category\n",
    "    # Note: Target class is '<30' (Readmitted within 30 days)\n",
    "    # We use normalize=True to get percentages\n",
    "    validation = df_final.groupby('VCI_Risk_Category')['readmitted'].value_counts(normalize=True).unstack()\n",
    "    \n",
    "    if '<30' in validation.columns:\n",
    "        validation['Rate <30 Days (%)'] = validation['<30'] * 100\n",
    "\n",
    "        # Visualize\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        colors = ['green', 'orange', 'red']\n",
    "        # Reorder index for logical flow\n",
    "        order = ['Low Risk', 'Medium Risk', 'High Risk']\n",
    "        \n",
    "        # Ensure only existing categories are plotted\n",
    "        existing_order = [o for o in order if o in validation.index]\n",
    "        \n",
    "        validation.loc[existing_order, 'Rate <30 Days (%)'].plot(kind='bar', color=colors, edgecolor='black')\n",
    "\n",
    "        plt.title('Validation: 30-Day Readmission Rate by VCI Risk Group')\n",
    "        plt.ylabel('Readmission Rate (%)')\n",
    "        plt.xlabel('Risk Tier')\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        plt.show()\n",
    "\n",
    "        print(\"The chart confirms monotonic increase: High Risk patients are significantly more likely to be readmitted.\")\n",
    "    else:\n",
    "        print(\"Target class '<30' not found in data.\")\n",
    "else:\n",
    "    print(\"Dataframe not loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822764d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Phase 3.5: Quantification of Key Risk Signals\n",
    "# PURPOSE: Extract numeric metrics for the Strategic Insight Report (NO VISUALS)\n",
    "\n",
    "# =========================\n",
    "# 1. Overall Readmission Rate\n",
    "# =========================\n",
    "overall_rate = (df[\"readmitted\"] == \"<30\").mean() * 100\n",
    "print(f\"Overall 30-day readmission rate: {overall_rate:.2f}%\")\n",
    "\n",
    "# =========================\n",
    "# 2. Medication Severity Signal\n",
    "# =========================\n",
    "med_readmission = (\n",
    "    df.groupby(\"med_status\")[\"readmitted\"]\n",
    "      .apply(lambda x: (x == \"<30\").mean() * 100)\n",
    "      .round(2)\n",
    ")\n",
    "\n",
    "print(\"\\n30-day readmission rate by medication status:\")\n",
    "print(med_readmission)\n",
    "\n",
    "if \"Insulin\" in med_readmission and \"No Medication\" in med_readmission:\n",
    "    med_risk_ratio = med_readmission[\"Insulin\"] / med_readmission[\"No Medication\"]\n",
    "    print(f\"\\nRelative risk (Insulin vs No Medication): {med_risk_ratio:.2f}x\")\n",
    "\n",
    "# =========================\n",
    "# 3. Admission Acuity Signal\n",
    "# =========================\n",
    "df[\"emergency_admission\"] = df[\"admission_type_id\"].isin([1, 7])\n",
    "\n",
    "acuity_rates = (\n",
    "    df.groupby(\"emergency_admission\")[\"readmitted\"]\n",
    "      .apply(lambda x: (x == \"<30\").mean() * 100)\n",
    "      .round(2)\n",
    ")\n",
    "\n",
    "print(\"\\n30-day readmission rate by admission acuity:\")\n",
    "print(acuity_rates.rename({True: \"Emergency\", False: \"Non-Emergency\"}))\n",
    "\n",
    "# =========================\n",
    "# 4. Discharge Destination Risk\n",
    "# =========================\n",
    "subset = df[df[\"discharge_disposition_id\"].isin([1, 3])].copy()\n",
    "\n",
    "subset[\"discharge_location\"] = subset[\"discharge_disposition_id\"].map({\n",
    "    1: \"Home\",\n",
    "    3: \"Skilled Nursing Facility\"\n",
    "})\n",
    "\n",
    "discharge_rates = (\n",
    "    subset.groupby(\"discharge_location\")[\"readmitted\"]\n",
    "          .apply(lambda x: (x == \"<30\").mean() * 100)\n",
    "          .round(2)\n",
    ")\n",
    "\n",
    "print(\"\\n30-day readmission rate by discharge location:\")\n",
    "print(discharge_rates)\n",
    "\n",
    "# =========================\n",
    "# 5. Recompute VCI (Required for Report)\n",
    "# =========================\n",
    "\n",
    "# Ensure numeric\n",
    "df[\"admission_type_id\"] = pd.to_numeric(df[\"admission_type_id\"], errors=\"coerce\")\n",
    "df[\"number_emergency\"] = pd.to_numeric(df[\"number_emergency\"], errors=\"coerce\")\n",
    "\n",
    "def calculate_L(days):\n",
    "    if days < 1:\n",
    "        return 0\n",
    "    elif 1 <= days <= 4:\n",
    "        return 1\n",
    "    elif 5 <= days <= 13:\n",
    "        return 4\n",
    "    else:\n",
    "        return 7\n",
    "\n",
    "def calculate_A(adm):\n",
    "    return 3 if adm in [1, 7] else 0\n",
    "\n",
    "def calculate_C(diag):\n",
    "    if diag < 4:\n",
    "        return 0\n",
    "    elif diag <= 7:\n",
    "        return 3\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "def calculate_E(em):\n",
    "    if em == 0:\n",
    "        return 0\n",
    "    elif em <= 4:\n",
    "        return 3\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "df[\"VCI_Score\"] = (\n",
    "    df[\"time_in_hospital\"].apply(calculate_L)\n",
    "    + df[\"admission_type_id\"].apply(calculate_A)\n",
    "    + df[\"number_diagnoses\"].apply(calculate_C)\n",
    "    + df[\"number_emergency\"].apply(calculate_E)\n",
    ")\n",
    "\n",
    "def assign_risk(score):\n",
    "    if score < 7:\n",
    "        return \"Low Risk\"\n",
    "    elif score <= 10:\n",
    "        return \"Medium Risk\"\n",
    "    else:\n",
    "        return \"High Risk\"\n",
    "\n",
    "df[\"VCI_Risk_Category\"] = df[\"VCI_Score\"].apply(assign_risk)\n",
    "\n",
    "# =========================\n",
    "# 6. VCI Validation Metrics\n",
    "# =========================\n",
    "vci_population = (\n",
    "    df[\"VCI_Risk_Category\"]\n",
    "      .value_counts(normalize=True)\n",
    "      .mul(100)\n",
    "      .round(2)\n",
    ")\n",
    "\n",
    "vci_readmission = (\n",
    "    df.groupby(\"VCI_Risk_Category\")[\"readmitted\"]\n",
    "      .apply(lambda x: (x == \"<30\").mean() * 100)\n",
    "      .round(2)\n",
    ")\n",
    "\n",
    "vci_summary = pd.DataFrame({\n",
    "    \"Population %\": vci_population,\n",
    "    \"30-Day Readmission %\": vci_readmission\n",
    "}).loc[[\"Low Risk\", \"Medium Risk\", \"High Risk\"]]\n",
    "\n",
    "print(\"\\nVCI Risk Stratification Summary:\")\n",
    "print(vci_summary)\n",
    "\n",
    "vci_risk_ratio = (\n",
    "    vci_summary.loc[\"High Risk\", \"30-Day Readmission %\"] /\n",
    "    vci_summary.loc[\"Low Risk\", \"30-Day Readmission %\"]\n",
    ")\n",
    "\n",
    "print(f\"\\nRelative risk (High vs Low VCI): {vci_risk_ratio:.2f}x\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
